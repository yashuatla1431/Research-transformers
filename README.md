# ðŸ§  Research Transformers

This repository contains my implementations and notes as I reproduce and expand the **Transformer** and **GPT** architectures from scratch â€” inspired by Andrej Karpathy's *Zero to Hero* series.

---

### ðŸ“˜ Current Progress

- [x] Watched and followed Karpathy's GPT-from-scratch tutorial  
- [ ] Rebuilding GPT architecture from memory (Week 1 goal)  
- [ ] Implementing Encoder-Decoder Transformer  
- [ ] Pretraining GPT-mini on TinyStories dataset  
- [ ] Fine-tuning on instruction datasets (Alpaca, Dolly)

---

### ðŸ“‚ Folder Structure
